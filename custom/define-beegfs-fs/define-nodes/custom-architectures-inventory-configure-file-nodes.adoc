---
sidebar: sidebar 
permalink: custom-architectures-inventory-configure-file-nodes.html 
keywords: BeeGFS on NetApp, NetApp Custom Architectures, EF600 
summary: 'Especifique la configuración de los nodos de archivos individuales con variables de host (host_var).' 
---
= Configurar nodos de archivos individuales
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
Especifique la configuración de los nodos de archivos individuales con variables de host (host_var).



== Descripción general

Esta sección recorre la relleno de un `host_vars/<FILE_NODE_HOSTNAME>.yml` archivo para cada nodo de archivo del clúster. Estos archivos sólo deben contener una configuración exclusiva de un nodo de archivo concreto. Esto incluye normalmente:

* Definición de la IP o el nombre de host que Ansible debe usar para conectarse al nodo.
* Configurar interfaces adicionales e IP de clúster utilizadas para los servicios de clúster de alta disponibilidad (Pacemaker y Corosync) para comunicarse con otros nodos de archivo. De forma predeterminada, estos servicios utilizan la misma red que la interfaz de gestión, pero deberían estar disponibles interfaces adicionales para la redundancia. La práctica común es definir IP adicionales en la red de almacenamiento, lo que evita la necesidad de un clúster o una red de gestión adicionales.
+
** El rendimiento de cualquier red utilizada para la comunicación del clúster no es crítico en cuanto al rendimiento del sistema de archivos. Con la configuración predeterminada del clúster, por lo general una red de al menos 1 Gbps ofrecerá un rendimiento suficiente para las operaciones del clúster, como la sincronización de los estados de nodo y la coordinación de los cambios de estado de los recursos del clúster. Las redes lentas/ocupadas pueden hacer que los cambios en el estado de los recursos tarden más de lo habitual y, en casos extremos, podrían resultar en que los nodos se expulsen del clúster si no pueden enviar latidos en un período de tiempo razonable.


* Configurar las interfaces utilizadas para conectarse a los nodos de bloques sobre el protocolo deseado (por ejemplo, iSCSI/Iser, NVMe/IB, NVMe/roce, FCP, etc.)




== Pasos

Hacer referencia al esquema de direccionamiento IP definido en link:custom-architectures-plan-file-system.html["Planifique el sistema de archivos"] para cada nodo de archivo del clúster, cree un archivo `host_vars/<FILE_NODE_HOSTNAME>/yml` y rellenarlo de la siguiente manera:

. En la parte superior, especifique la IP o el nombre de host que Ansible debe usar a SSH del nodo y gestiónelo:
+
[source, yaml]
----
ansible_host: "<MANAGEMENT_IP>"
----
. Configure las IP adicionales que se puedan usar para el tráfico del clúster:
+
.. Si el tipo de red es link:https://github.com/netappeseries/host/tree/release-1.2.0/roles/ipoib["InfiniBand (uso de IPoIB)"^]:
+
[source, yaml]
----
eseries_ipoib_interfaces:
- name: <INTERFACE>  # Example: ib0 or i1b
  address: <IP/SUBNET> # Example: 100.127.100.1/16
- name: <INTERFACE>  # Additional interfaces as needed.
  address: <IP/SUBNET>
----
.. Si el tipo de red es link:https://github.com/netappeseries/host/tree/release-1.2.0/roles/roce["RDMA sobre Ethernet convergente (roce)"^]:
+
[source, yaml]
----
eseries_roce_interfaces:
- name: <INTERFACE>  # Example: eth0.
  address: <IP/SUBNET> # Example: 100.127.100.1/16
- name: <INTERFACE>  # Additional interfaces as needed.
  address: <IP/SUBNET>
----
.. Si el tipo de red es link:https://github.com/netappeseries/host/tree/release-1.2.0/roles/ip["Ethernet (solo TCP, sin RDMA)"^]:
+
[source, yaml]
----
eseries_ip_interfaces:
- name: <INTERFACE>  # Example: eth0.
  address: <IP/SUBNET> # Example: 100.127.100.1/16
- name: <INTERFACE>  # Additional interfaces as needed.
  address: <IP/SUBNET>
----


. Indique qué IP se deben utilizar para el tráfico del clúster con las IP preferidas más alta:
+
[source, yaml]
----
beegfs_ha_cluster_node_ips:
- <MANAGEMENT_IP> # Including the management IP is typically but not required.
- <IP_ADDRESS>    # Ex: 100.127.100.1
- <IP_ADDRESS>    # Additional IPs as needed.
----
+

NOTE: Los IPS configurados en el paso dos no se utilizarán como IP de clúster a menos que estén incluidos en el `beegfs_ha_cluster_node_ips` lista. Esto le permite configurar IP/interfaces adicionales con Ansible que pueden utilizarse para otros fines si así lo desea.

. Si el nodo de archivo tiene que comunicarse con los nodos de bloque a través de un protocolo basado en IP, se deberán configurar las IP en la interfaz adecuada y con todos los paquetes necesarios para instalar y configurar ese protocolo.
+
.. Si se utiliza link:https://github.com/netappeseries/host/blob/master/roles/iscsi/README.md["ISCSI"^]:
+
[source, yaml]
----
eseries_iscsi_interfaces:
- name: <INTERFACE>  # Example: eth0.
  address: <IP/SUBNET> # Example: 100.127.100.1/16
----
.. Si se utiliza link:https://github.com/netappeseries/host/blob/master/roles/ib_iser/README.md["Iser"^]:
+
[source, yaml]
----
eseries_ib_iser_interfaces:
- name: <INTERFACE>  # Example: ib0.
  address: <IP/SUBNET> # Example: 100.127.100.1/16
  configure: true # If the file node is directly connected to the block node set to true to setup OpenSM.
----
.. Si se utiliza link:https://github.com/netappeseries/host/blob/master/roles/nvme_ib/README.md["NVMe/IB"^]:
+
[source, yaml]
----
eseries_nvme_ib_interfaces:
- name: <INTERFACE>  # Example: ib0.
  address: <IP/SUBNET> # Example: 100.127.100.1/16
  configure: true # If the file node is directly connected to the block node set to true to setup OpenSM.
----
.. Si se utiliza link:https://github.com/netappeseries/host/blob/master/roles/nvme_roce/README.md["NVMe/roce"^]:
+
[source, yaml]
----
eseries_nvme_roce_interfaces:
- name: <INTERFACE>  # Example: eth0.
  address: <IP/SUBNET> # Example: 100.127.100.1/16
----
.. Otros protocolos:
+
... Si se utiliza link:https://github.com/netappeseries/host/blob/master/roles/nvme_fc/README.md["NVMe/FC"^], no es necesario configurar interfaces individuales. La implementación del clúster BeeGFS detectará automáticamente los requisitos de protocolo e instalará/configurará según sea necesario. Si utiliza una estructura para conectar nodos de archivos y bloques, asegúrese de que los switches se dividen correctamente siguiendo las prácticas recomendadas de NetApp y del proveedor del switch.
... El uso de FCP o SAS no requiere la instalación ni la configuración de software adicional. Si utiliza FCP, asegúrese de que los switches se dividen correctamente a continuación link:https://docs.netapp.com/us-en/e-series/config-linux/fc-configure-switches-task.html["NetApp"^] y las prácticas recomendadas de su proveedor del switch.
... No se recomienda el uso de SRP IB en este momento. Utilice NVMe/IB o Iser en función de lo que admita su nodo de bloque E-Series.






Haga clic en link:https://github.com/netappeseries/beegfs/blob/master/getting_started/beegfs_on_netapp/gen2/host_vars/ictad22h01.yml["aquí"^] para obtener un ejemplo de un archivo de inventario completo que representa un solo nodo de archivo.



=== Avanzado: Alternar los adaptadores VPI NVIDIA ConnectX entre Ethernet y modo InfiniBand

Los adaptadores NVIDIA ConnectX-Virtual Protocol Interconnect&reg; (VPI) admiten InfiniBand y Ethernet como capa de transporte. El cambio entre modos no se negocia automáticamente y se debe configurar mediante el `mstconfig` herramienta incluida en `mstflint`, un paquete de código abierto que forma parte de link:https://docs.nvidia.com/networking/display/MFTV4133/MFT+Supported+Configurations+and+Parameters["Herramientas Mellanox Firmare (MFT)"^]. El cambio del modo de los adaptadores solo debe realizarse una vez. Esto se puede realizar manualmente o incluso en el inventario de Ansible como parte de las interfaces configuradas con el `eseries-[ib|ib_iser|ipoib|nvme_ib|nvme_roce|roce]_interfaces:` sección del inventario, para que se compruebe/aplique automáticamente.

Por ejemplo, para cambiar una interfaz actual en modo InfiniBand a Ethernet, se puede utilizar para roce:

. Especifique para cada interfaz que desee configurar `mstconfig` como una asignación (o diccionario) que especifica `LINK_TYPE_P<N>` donde `<N>` Viene determinado por el número de puerto de HCA de la interfaz. La `<N>` el valor se puede determinar ejecutando `grep PCI_SLOT_NAME /sys/class/net/<INTERFACE_NAME>/device/uevent` Y agregando 1 al último número desde el nombre de la ranura PCI y convirtiendo a decimal.
+
.. Por ejemplo dado `PCI_SLOT_NAME=0000:2f:00.2` (2 + 1 -> puerto HCA 3) -> `LINK_TYPE_P3: eth`:
+
[source, yaml]
----
eseries_roce_interfaces:
- name: <INTERFACE>
  address: <IP/SUBNET>
  mstconfig:
    LINK_TYPE_P3: eth
----




Para obtener información adicional, consulte link:https://github.com/netappeseries/host["Documentación de la colección de hosts E-Series de NetApp"^] para el tipo/protocolo de interfaz que utiliza.
